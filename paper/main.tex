\documentclass[10pt,twocolumn]{article}

% Page layout - ICML style
\usepackage[margin=1in]{geometry}
\usepackage{times}

% Standard packages
\usepackage{microtype}
\usepackage{graphicx}
\usepackage{booktabs}
\usepackage{amsmath}
\usepackage{amssymb}
\usepackage{amsthm}
\usepackage{algorithm}
\usepackage{algorithmic}
\usepackage{natbib}
\usepackage{hyperref}
\usepackage{xcolor}
\usepackage{enumitem}
\usepackage{multirow}
\usepackage{tabularx}

% Compact lists
\setlist{nosep,leftmargin=*}

% Hyperref setup
\hypersetup{
    colorlinks=true,
    linkcolor=blue!70!black,
    citecolor=blue!70!black,
    urlcolor=blue!70!black
}

% Theorem environments
\newtheorem{theorem}{Theorem}
\newtheorem{lemma}[theorem]{Lemma}
\newtheorem{corollary}[theorem]{Corollary}
\newtheorem{proposition}[theorem]{Proposition}
\newtheorem{assumption}{Assumption}
\newtheorem{definition}{Definition}
\newtheorem{example}{Example}
\newtheorem{remark}{Remark}

% Custom commands
\newcommand{\E}{\mathbb{E}}
\newcommand{\R}{\mathbb{R}}
\newcommand{\Var}{\mathrm{Var}}
\newcommand{\Cov}{\mathrm{Cov}}
\newcommand{\bX}{\mathbf{X}}
\newcommand{\bx}{\mathbf{x}}
\newcommand{\by}{\mathbf{y}}
\newcommand{\bz}{\mathbf{z}}
\newcommand{\bbeta}{\boldsymbol{\beta}}
\newcommand{\btheta}{\boldsymbol{\theta}}
\newcommand{\bpsi}{\boldsymbol{\psi}}
\newcommand{\btau}{\boldsymbol{\tau}}

% Algorithm style
\renewcommand{\algorithmicrequire}{\textbf{Input:}}
\renewcommand{\algorithmicensure}{\textbf{Output:}}

\begin{document}

%============================================================================
% Title Block
%============================================================================
\makeatletter
\twocolumn[
\begin{@twocolumnfalse}
\begin{center}
{\LARGE\bfseries Double Machine Learning for AI Data Augmentation\\in Generalized Linear Models\par}
\vskip 1em
{\large
Cheng Lu$^1$ \quad Mengxin Wang$^2$ \quad Dennis J.\ Zhang$^1$ \quad Heng Zhang$^3$
\par}
\vskip 0.5em
{\small
$^1$Olin Business School, Washington University in St.\ Louis\\
$^2$Naveen Jindal School of Management, University of Texas at Dallas\\
$^3$W.P.\ Carey School of Business, Arizona State University\\[0.3em]
\texttt{\{cheng.lu, denniszhang\}@wustl.edu}, \texttt{mengxin.wang@utdallas.edu}, \texttt{hengzhang24@asu.edu}
\par}
\vskip 1em

%============================================================================
% Abstract
%============================================================================
\begin{minipage}{0.92\textwidth}
\textbf{Abstract.}
Large language models enable cheap AI annotations, but leveraging them for valid statistical inference remains challenging. Naive pooling introduces bias; Prediction-Powered Inference (PPI) requires AI outputs to directly approximate outcomes---violated when predictions are categorical or accuracy is moderate. We propose a Double Machine Learning framework that treats AI predictions as \textit{informative features} rather than outcome surrogates, learning $g(X,z) = \E[y|X,z]$ nonparametrically. Our Neyman-orthogonal score functions remain computable when human labels are missing, enabling valid inference on combined primary (human-labeled) and auxiliary (AI-augmented) data. We prove asymptotic normality and variance dominance over primary-only estimation under random selection. On conjoint analysis with GPT-4o (57\% accuracy), DML achieves 16.5\% MAPE versus 32.0\% (primary-only), 17.6\% (AAE), and 51.1\% (PPI). The key insight: AI predictions should enter estimation as features, not proxies.
\end{minipage}
\vskip 1.5em
\end{center}
\end{@twocolumnfalse}
]
\makeatother

%============================================================================
\section{Introduction}
\label{sec:intro}
%============================================================================

The emergence of large language models (LLMs) has fundamentally transformed the economics of data collection. Models like GPT-4 can annotate text, answer surveys, and produce labels at costs orders of magnitude lower than human annotation \citep{brown2020language, openai2023gpt4}. This capability is transformative across empirical research: conjoint analysis in marketing (\$5--20 per respondent; \citealp{sawtooth2017conjoint}), medical image annotation (\$50--500 per case), sentiment analysis for social science (\$0.50--2 per document), and legal document review (\$25--150 per hour). When LLM API calls cost \$0.01--0.10 per annotation, the potential for 10--1000$\times$ cost reduction is enormous. While we demonstrate our framework on conjoint analysis, the methodology applies to any GLM estimation task where AI predictions are available.

However, realizing these savings while maintaining statistical validity presents fundamental challenges. AI predictions differ systematically from human judgments in ways that are difficult to characterize \textit{a priori}. A naive approach that pools AI and human labels as interchangeable introduces bias that can overwhelm any efficiency gains. The central question is: \textit{How can we leverage abundant AI-generated data to improve estimation efficiency while maintaining valid statistical inference?}

\textbf{Existing Approaches and Their Limitations.} Two prominent frameworks address this question. \textit{Prediction-Powered Inference} (PPI) \citep{angelopoulos2023prediction} constructs confidence intervals by treating AI predictions $\bz$ as direct proxies for outcomes $\by$, correcting for the prediction error $\bz - \by$ using labeled data. This elegant approach provides valid inference under the assumption that $\bz \approx \by$. However, when AI accuracy is moderate---as is common with LLMs on complex judgment tasks---PPI's correction term amplifies rather than reduces variance. In our experiments with 57\% AI accuracy, PPI achieves only 51.1\% MAPE (after filtering AI abstentions) versus 16.5\% for our method.

The \textit{Assumption-lean and Data-adaptive} (AAE) framework \citep{wang2024llm} applies transfer learning to debias LLM predictions. While effective, AAE assumes a parametric relationship between AI and human responses, limiting flexibility when this relationship is complex or heterogeneous across the feature space.

\textbf{Our Approach.} We propose a fundamentally different perspective based on Double Machine Learning (DML) \citep{chernozhukov2018double}. Rather than treating AI predictions as noisy versions of human labels ($\bz \approx \by$), we treat them as \textit{informative features} that help predict the conditional expectation of outcomes: $g(\bX, \bz) = \E[\by | \bX, \bz]$. This shift in perspective has profound implications:

\begin{enumerate}
    \item \textbf{Flexibility}: The relationship between $\bz$ and $\by$ can be learned nonparametrically, accommodating arbitrary dependence structures including cases where AI systematically errs on certain feature combinations.
    \item \textbf{Computability}: Our score function remains well-defined even when $\by$ is unobserved, enabling use of all auxiliary data.
    \item \textbf{Validity}: Neyman orthogonality ensures valid asymptotic inference even when nuisance functions are estimated at slower-than-parametric rates.
    \item \textbf{Efficiency}: We prove dominance over primary-only estimation---our estimator achieves strictly smaller asymptotic variance when AI predictions carry information about outcomes.
\end{enumerate}

\textbf{Contributions.} Our contributions are threefold:
\begin{itemize}
    \item We develop a DML framework for AI data augmentation in canonical GLMs, constructing Neyman-orthogonal score functions that enable valid inference with partially observed outcomes (Section~\ref{sec:method}).
    \item We establish asymptotic normality (Theorem~\ref{thm:normality}) and prove variance dominance over primary-only estimation under random selection (Corollary~\ref{cor:dominance}), with complete proofs in Appendix~\ref{app:proofs}.
    \item We demonstrate through experiments on conjoint analysis that DML achieves 16.5\% MAPE, improving over primary-only (32.0\%), AAE (17.6\%), and PPI (51.1\%; Section~\ref{sec:experiments}).
\end{itemize}

\noindent Code is available at \url{https://github.com/anonymous/dml-augmentation}.

\textbf{Paper Organization.} Section~\ref{sec:related} reviews related work. Section~\ref{sec:problem} formalizes the problem. Section~\ref{sec:method} presents our methodology. Section~\ref{sec:theory} establishes theoretical guarantees. Section~\ref{sec:experiments} provides empirical evaluation. Section~\ref{sec:conclusion} concludes.

%============================================================================
\section{Related Work}
\label{sec:related}
%============================================================================

\textbf{Prediction-Powered Inference.} \citet{angelopoulos2023prediction} introduced PPI for constructing valid confidence intervals by leveraging ML predictions on unlabeled data. PPI uses labeled data to estimate and correct for the bias in predictions, yielding valid inference when predictions are reasonably accurate proxies for outcomes. When predictions are continuous and well-calibrated, PPI achieves substantial efficiency gains. However, PPI's variance reduction depends on prediction quality: the correction term $\hat{\theta}_{\text{rect}} = \frac{1}{n}\sum_{i \in \text{labeled}}(f(X_i) - Y_i)$ has variance that grows when predictions poorly approximate outcomes. In our setting, AI outputs are categorical ($z \in \{-1,0,1\}$) rather than continuous probability estimates, violating the implicit assumption that $z$ and $y$ live in the same space. Our framework instead treats $z$ as a \textit{feature} for predicting $\E[y|X,z]$, which remains valid regardless of AI accuracy.

\textbf{Double Machine Learning and Doubly Robust Estimation.} \citet{chernozhukov2018double} developed DML for causal inference with high-dimensional nuisance parameters, building on the doubly robust estimation literature \citep{bang2005doubly, robins1994estimation}. The Neyman orthogonality condition ensures that estimation error in nuisance functions has only second-order effects on target parameters. Our score function (Equation~\ref{eq:score}) shares the doubly robust structure: it remains consistent if either $e$ or $g$ is correctly specified, though we require both for efficiency. \citet{kennedy2022semiparametric} provides a comprehensive review of these connections.

\textbf{Semi-Supervised and Transfer Learning.} Classical semi-supervised methods \citep{chapelle2006semi, zhu2009introduction} use unlabeled features to improve prediction. Transfer learning \citep{pan2009survey, weiss2016survey} addresses distribution shift between domains. Our setting is distinct: we have AI-generated \textit{labels} (not just features) for auxiliary data, but these labels may be systematically biased. The AAE framework \citep{wang2024llm} addresses this through parametric debiasing; we provide a nonparametric alternative that can capture complex, heterogeneous relationships between AI and human responses.

\textbf{Missing Data.} Our framework connects to missing data theory \citep{little2019statistical, rubin1976inference}, where human labels are ``missing'' for auxiliary observations. The inverse probability weighting term $w/e$ in our score function mirrors classical IPW estimators \citep{robins1994estimation}, while the $g$ function provides augmentation analogous to AIPW \citep{scharfstein1999adjusting}. The key distinction is that we observe AI predictions $\bz$ for all observations, providing rich auxiliary information beyond the missingness indicator.

%============================================================================
\section{Problem Formulation}
\label{sec:problem}
%============================================================================

\subsection{Setting and Notation}

Consider a dataset $\mathcal{D} = \{\Xi_i = (\bX_i, \by_i, w_i, \bz_i)\}_{i=1}^n$ of i.i.d.\ observations where:
\begin{itemize}
    \item $\bX \in \mathcal{X} \subset \R^{k \times d}$: bounded feature matrix
    \item $\by \in \R^k$: human label of interest (partially observed)
    \item $w \in \{0,1\}$: indicator for whether human label is observed
    \item $\bz$: AI-generated auxiliary data (structure unrestricted)
\end{itemize}

The data partitions into \textit{primary data} $\mathcal{D}^P = \{i : w_i = 1\}$ with observed human labels, and \textit{auxiliary data} $\mathcal{D}^A = \{i : w_i = 0\}$ with only AI predictions.

\subsection{Generalized Linear Models}

Let $b(\cdot): \Theta \to \R$ be a known convex function on open convex $\Theta \subset \R^k$. The target parameter $\bbeta^* \in \mathcal{B} \subset \R^d$ solves:
\begin{equation}
    \bbeta^* \in \arg\min_{\bbeta \in \mathcal{B}} \E\left[b(\bX\bbeta) - \by^\top \bX\bbeta\right]
    \label{eq:population}
\end{equation}
satisfying the first-order condition:
\begin{equation}
    \E\left[\bX^\top \left(\nabla b(\bX\bbeta^*) - \by\right)\right] = 0
    \label{eq:foc}
\end{equation}

This framework encompasses canonical GLMs: linear regression ($b(\theta) = \frac{1}{2}\theta^2$), logistic regression ($b(\theta) = \log(1+e^\theta)$), Poisson regression ($b(\theta) = e^\theta$), and multinomial logit ($b(\btheta) = \log(1 + \sum_j e^{\theta_j})$). Importantly, our framework allows misspecification---$\bbeta^*$ is the pseudo-true parameter minimizing KL divergence to the GLM family.

\subsection{Selection Mechanism}

We assume human labels are unobserved at random: $w \perp \by | \bX, \bz$. Define:
\begin{itemize}
    \item Propensity score: $e^*(\bX, \bz) = \E[w | \bX, \bz] > \kappa$ for some $\kappa > 0$
    \item Conditional expectation: $g^*(\bX, \bz) = \E[\by | \bX, \bz]$
\end{itemize}

The conditional independence assumption is natural when primary data collection is designed (e.g., random sampling of human annotations) rather than observational.

%============================================================================
\section{Methodology}
\label{sec:method}
%============================================================================

\subsection{The Challenge}

The standard score function $\nabla_\bbeta \ell(\bX, \by; \bbeta) = \bX^\top(\nabla b(\bX\bbeta) - \by)$ requires observing $\by$, making it inapplicable to auxiliary data where $w=0$. Our key contribution is an alternative score function that:
\begin{enumerate}
    \item Equals zero at the true parameter in expectation
    \item Remains computable when $\by$ is unobserved
    \item Satisfies Neyman orthogonality for valid inference
\end{enumerate}

\subsection{The DML Score Function}

We propose the score function:
\begin{equation}
    \bpsi(\Xi; e, g; \bbeta) := \bX^\top \left[\nabla b(\bX\bbeta) - g(\bX, \bz) + \frac{w}{e(\bX, \bz)}(g(\bX, \bz) - \by)\right]
    \label{eq:score}
\end{equation}

\textbf{Key Properties:}
\begin{enumerate}
    \item \textbf{Computability}: When $w=0$, the score simplifies to $\bX^\top[\nabla b(\bX\bbeta) - g(\bX, \bz)]$, requiring only features $\bX$, AI predictions $\bz$, and the learned function $g$.

    \item \textbf{Unbiasedness}: At true parameters,
    \begin{align}
        \E[\bpsi(\Xi; e^*, g^*; \bbeta^*)] &= \E[\bX^\top(\nabla b(\bX\bbeta^*) - \by)] = 0
    \end{align}
    where the second term in~\eqref{eq:score} has zero expectation by iterated expectations and the definitions of $e^*$ and $g^*$.

    \item \textbf{Neyman Orthogonality}: The pathwise derivative of $\E[\bpsi]$ with respect to $(e,g)$ vanishes at $(e^*, g^*)$, ensuring robustness to nuisance estimation error.
\end{enumerate}

\textbf{Technical Novelty.} While our estimator builds on the DML framework of \citet{chernozhukov2018double}, several aspects are specific to the AI augmentation setting: (i) the score function~\eqref{eq:score} is constructed to handle \textit{partially observed outcomes}---standard DML assumes $y$ is always observed; (ii) the nuisance function $g(X,z) = \E[y|X,z]$ explicitly incorporates AI predictions as conditioning variables, enabling nonparametric learning of the AI-human relationship; (iii) our dominance result (Corollary~\ref{cor:dominance}) characterizes precisely when augmented data improves efficiency, which is novel to this setting. The key conceptual contribution is recognizing that AI predictions should enter as \textit{features} in $g(\cdot)$, not as direct outcome proxies.

\subsection{Intuition: DML-Adjusted Targets}

Setting the score to zero and solving for effective targets $\tau$ yields:
\begin{align}
    \text{Primary } (w=1): \quad \tau &= g\left(1 - \frac{1}{e}\right) + \frac{y}{e} \label{eq:tau_primary}\\
    \text{Auxiliary } (w=0): \quad \tau &= g \label{eq:tau_aux}
\end{align}

For primary data, the target blends the model prediction $g$ with the debiased human label $y/e$. For auxiliary data, we use the model prediction directly. The weighting by $1/e$ upweights primary observations to correct for their relative scarcity.

\subsection{The DML Algorithm}

\begin{algorithm}[t]
\caption{DML for AI-Augmented GLMs}
\label{alg:dml}
\begin{algorithmic}[1]
\REQUIRE Data $\mathcal{D}$, number of folds $K$
\STATE Partition primary data $\mathcal{D}^P$ into $K$ folds $I_1, \ldots, I_K$
\FOR{$k = 1, \ldots, K$}
    \STATE Train $\hat{g}$ on primary data $\mathcal{D}^P \setminus I_k$ using logistic regression
    \STATE Compute DML targets: $\hat{\tau}_i = \hat{g}(X_i, z_i)(1 - 1/\hat{e}) + w_i y_i/\hat{e}$ for all $i$
    \STATE Fit GLM: $\hat{\bbeta}_k = \arg\min_{\bbeta} \sum_{i \in I_k \cup \mathcal{D}^A} [b(\bX_i\bbeta) - \hat{\tau}_i^\top \bX_i\bbeta]$
\ENDFOR
\RETURN $\hat{\bbeta} = \frac{1}{K}\sum_{k=1}^K \hat{\bbeta}_k$
\end{algorithmic}
\end{algorithm}

\textbf{Implementation Notes.} Step 3 trains $\hat{g}$ on primary data excluding fold $k$, ensuring out-of-sample predictions. Under random selection, $\hat{e} = n_P/(n_P + n_A)$ is constant (no model needed). Step 5 fits a standard GLM with DML-adjusted targets $\hat{\tau}$, solvable by any convex optimizer. Computational overhead is modest: $K$ logistic regressions on $O(n_P)$ samples plus $K$ GLM fits on $O(n_P + n_A)$ samples, totaling $O(K \cdot (n_P + n_A) \cdot d)$ operations.

\subsection{Simplification Under Random Selection}

In many applications, selection into primary data is by design (random sampling) rather than observational. This yields a key simplification:

\begin{corollary}[Constant Propensity]
\label{cor:constant_e}
When $w \perp (\bX, \by, \bz)$, the propensity score is constant: $e(\bX, \bz) = \rho = n_P/(n_P + n_A)$. No propensity model is needed.
\end{corollary}

This eliminates one nuisance function entirely, simplifying implementation and reducing estimation error.

%============================================================================
\section{Theoretical Results}
\label{sec:theory}
%============================================================================

\subsection{Assumptions}

\begin{assumption}[Regularity]
\label{ass:regularity}
(i) $\bX \in \mathcal{X}$ is bounded; (ii) $b(\cdot)$ is twice continuously differentiable with $\nabla^2 b(\theta) \succ 0$ on $\Theta$; (iii) $\E[\bX^\top \bX]$ is positive definite; (iv) $\|\Cov(\by|\bX,\bz)\| \leq \tilde{\sigma}^2$.
\end{assumption}

\begin{assumption}[ML Convergence Rate]
\label{ass:ml_rate}
There exists $\alpha(n) \downarrow 0$ and $r_1 + r_2 \geq 1/2$ such that:
\begin{align}
    \|\hat{e} - e^*\|_{P,2} &\leq \alpha(n)/n^{r_1} \\
    \|\hat{g} - g^*\|_{P,2} &\leq \alpha(n)/n^{r_2}
\end{align}
and $\sup_{\bX,\bz}|\hat{e} - e^*| \to_P 0$.
\end{assumption}

The product rate condition $r_1 + r_2 \geq 1/2$ is standard in DML and satisfied by many ML methods including random forests, neural networks, and boosting when the underlying functions have sufficient smoothness. In our implementation, logistic regression for $\hat{g}$ achieves $r_2 = 1/2$ under standard regularity conditions \citep{vandervaart2000asymptotic}, and under random selection $\hat{e} = e^*$ exactly (so $r_1 = \infty$), easily satisfying the requirement.

\subsection{Main Results}

Define the information matrix $\mathbf{J} := \E[\bX^\top \nabla^2 b(\bX\bbeta^*) \bX]$.

\begin{theorem}[Asymptotic Normality]
\label{thm:normality}
Under Assumptions~\ref{ass:regularity}--\ref{ass:ml_rate},
\begin{equation}
    \sqrt{n}(\hat{\bbeta} - \bbeta^*) \rightsquigarrow N(0, \mathbf{\Sigma}^{\text{DML}})
\end{equation}
where $\mathbf{\Sigma}^{\text{DML}} = \mathbf{J}^{-1} \E[\bpsi\bpsi^\top] \mathbf{J}^{-1}$.
\end{theorem}

The proof (Appendix~\ref{app:proof_normality}) proceeds by: (1) establishing score validity and Neyman orthogonality (Lemma~\ref{lem:score}); (2) proving consistency via convexity arguments (Lemma~\ref{lem:consistency}); (3) deriving the asymptotic expansion using Donsker theory.

\begin{corollary}[Dominance over Primary-Only]
\label{cor:dominance}
Let $\hat{\bbeta}^P$ be the primary-only estimator. If $e(\bX,\bz) = \rho$ is constant and $w \perp (\bX, \by, \bz)$, then:
\begin{equation}
    \mathbf{\Sigma}^P \succeq \mathbf{\Sigma}^{\text{DML}}
\end{equation}
with strict inequality when $\rho < 1$ and $\E[\bX^\top(\nabla b(\bX\bbeta^*) - g^*)(\nabla b(\bX\bbeta^*) - g^*)^\top \bX] \succ 0$.
\end{corollary}

\textbf{Interpretation.} The strict inequality condition holds whenever AI predictions are \textit{informative}---meaning $g^*(\bX,\bz)$ differs from the GLM's fitted values $\nabla b(\bX\bbeta^*)$. Intuitively, this occurs when AI predictions provide information about $y$ beyond what $X$ alone captures. If AI predictions were uninformative (random noise), we would have $g^*(X,z) = \E[y|X]$, and augmented data would not help. In practice, even 57\% accurate predictions satisfy this condition because they reveal systematic patterns in the AI-human relationship.

The proof (Appendix~\ref{app:proof_dominance}) decomposes the variance into two terms: one depending on $\zeta = \bX^\top(\nabla b - g^*)$ (model-prediction error) and one on $\pi = \bX^\top(g^* - \by)$ (irreducible noise). DML reduces the first term by factor $\rho$ through auxiliary data, while the second remains unchanged.

\begin{remark}[When Dominance Fails]
\label{rem:dominance_fail}
The dominance result requires random selection ($w \perp (X,y,z)$). When selection is informative---e.g., human labels are preferentially collected for ``hard'' cases where AI is uncertain---the primary-only estimator may achieve lower variance by focusing on high-information observations. Appendix~\ref{app:applications} provides a formal counterexample. In practice, dominance holds when primary data collection follows a designed sampling scheme rather than adaptive selection.
\end{remark}

\subsection{Variance Estimation}

For inference, we estimate the asymptotic variance using the plug-in principle:
\begin{equation}
    \hat{\mathbf{\Sigma}} = \hat{\mathbf{J}}^{-1} \left(\frac{1}{n}\sum_{i=1}^n \hat{\bpsi}_i \hat{\bpsi}_i^\top\right) \hat{\mathbf{J}}^{-1}
    \label{eq:var_est}
\end{equation}
where $\hat{\mathbf{J}} = \frac{1}{n}\sum_{i=1}^n \bX_i^\top \nabla^2 b(\bX_i\hat{\bbeta})\bX_i$ and $\hat{\bpsi}_i = \bpsi(\Xi_i; \hat{e}, \hat{g}; \hat{\bbeta})$. Standard errors for $\hat{\beta}_j$ are then $\text{SE}(\hat{\beta}_j) = \sqrt{\hat{\Sigma}_{jj}/n}$, enabling construction of confidence intervals and hypothesis tests.

%============================================================================
\section{Experiments}
\label{sec:experiments}
%============================================================================

\subsection{Conjoint Analysis Setting}

Conjoint analysis is a foundational method in marketing for measuring consumer preferences \citep{green1990conjoint, louviere2000stated}. Respondents choose between product alternatives characterized by attributes, and researchers estimate the utility weights (part-worths) governing these choices.

\textbf{Data.} Following \citet{wang2024llm}, we use a sports car conjoint study with 11 attributes (Table~\ref{tab:attributes}). Each choice task presents two cars; respondents select their preferred option. The ground truth parameters $\bbeta^* \in \R^{11}$ are estimated from a large-scale study ($n > 10,000$).

\begin{table}[t]
\caption{Sports car conjoint attributes. WTP values are illustrative, computed as $\beta^* / \beta_{\text{price}}$ to convert utility units to dollars; actual magnitudes depend on the price coefficient normalization.}
\label{tab:attributes}
\vskip 0.1in
\centering
\small
\begin{tabular}{@{}lcc@{}}
\toprule
Attribute & Levels & WTP (illustrative) \\
\midrule
Body Style & Coupe/Convert. & \$4.2K \\
Transmission & Auto/Manual & \$1.8K \\
Engine & V6/V8/V12 & \$6.1K \\
Fuel Economy & 18/22/26 mpg & \$3.4K \\
Top Speed & 140/160/180 mph & \$5.7K \\
Warranty & 3/5/7 years & \$2.9K \\
Safety Rating & 3/4/5 stars & \$4.5K \\
Entertainment & Basic/Premium & \$1.2K \\
Brand & A/B/C/D & \$3.8K \\
Color & 5 options & \$0.9K \\
Price & \$35K--\$65K & ---\\
\bottomrule
\end{tabular}
\vskip -0.1in
\end{table}

\textbf{AI Predictions.} We prompt GPT-4o with each choice task and record its prediction $z \in \{-1, 0, 1\}$: choose option 1 ($z=1$), choose option 2 ($z=0$), or abstain ($z=-1$). GPT-4o achieves 57\% accuracy (excluding abstentions). This modest accuracy---only 7 percentage points above random guessing---reflects the genuine difficulty of predicting heterogeneous human preferences: individual respondents weight attributes differently based on unobserved factors (budget constraints, lifestyle, taste), making aggregate prediction inherently challenging even for state-of-the-art LLMs. This low-accuracy regime is precisely where methods assuming $z \approx y$ struggle, making it a stringent test of our approach.

\textbf{Experimental Design.} We vary primary sample size $n_P \in \{50, 100, 150, 200\}$ with fixed $n_A = 1000$ auxiliary observations. Each configuration runs 30 trials with identical random seeds across methods for fair comparison.

\subsection{Methods Compared}

\begin{enumerate}
    \item \textbf{DML}: Our method with 5-fold cross-fitting, stratified logistic regression for $g$ with regularization $C=0.05$
    \item \textbf{AAE}: Assumption-lean method from \citet{wang2024llm}
    \item \textbf{Primary Only}: Standard MLE using only human-labeled data
    \item \textbf{Naive}: Pooling human and AI labels without correction
    \item \textbf{PPI}: Prediction-Powered Inference \citep{angelopoulos2023prediction}, excluding $z=-1$ abstentions
\end{enumerate}

\subsection{Main Results}

We evaluate methods using Mean Absolute Percentage Error (MAPE) relative to ground truth parameters:
\begin{equation}
    \text{MAPE} = \frac{100}{d} \sum_{j=1}^{d} \frac{|\hat{\beta}_j - \beta^*_j|}{|\beta^*_j|}
    \label{eq:mape}
\end{equation}
Table~\ref{tab:main} presents MAPE across methods.

\begin{table}[t]
\caption{Benchmark comparison (MAPE \%, lower is better). All methods use identical sample paths per trial.}
\label{tab:main}
\vskip 0.1in
\centering
\small
\begin{tabular}{@{}lccccc@{}}
\toprule
Method & $n$=50 & $n$=100 & $n$=150 & $n$=200 & Avg \\
\midrule
\textbf{DML} & \textbf{17.4} & \textbf{16.8} & \textbf{16.3} & \textbf{15.5} & \textbf{16.5} \\
AAE & 20.9 & 17.0 & 16.4 & 16.2 & 17.6 \\
Primary & 55.6 & 29.8 & 22.7 & 19.9 & 32.0 \\
PPI & 93.3 & 48.5 & 34.0 & 28.8 & 51.1 \\
Naive & 128.6 & 100.7 & 85.3 & 73.6 & 97.0 \\
\bottomrule
\end{tabular}
\vskip -0.1in
\end{table}

\textbf{DML achieves state-of-the-art performance.} With 16.5\% average MAPE, DML outperforms all baselines. The 15.5 percentage point improvement over Primary Only (32.0\%) demonstrates the value of AI augmentation. The 1.1 point improvement over AAE (17.6\%) reflects the benefit of nonparametric $g$-modeling.

\textbf{PPI fails due to violated assumptions.} PPI assumes $\bz \approx \by$, but GPT-4o's 57\% accuracy means this assumption is severely violated. After filtering abstentions, PPI achieves 51.1\% MAPE---worse than Primary Only. Without filtering, PPI produces MAPE $>$ 300\%. This illustrates the danger of assuming AI predictions directly proxy outcomes.

\subsection{Economic Interpretation}

In conjoint analysis, parameters represent willingness-to-pay (WTP) for attribute improvements. With average true WTP of \$3.5K per attribute, DML's 16.5\% MAPE translates to \$580 error per attribute versus \$1,120 for Primary Only---nearly double. For a product with 11 attributes, this compounds to \$6,380 vs.\ \$12,320 total error, potentially leading to substantially different pricing and product design decisions. Table~\ref{tab:wtp} in Appendix~\ref{app:experiments} provides the complete economic breakdown.

\subsection{Why Does DML Outperform PPI?}

The key difference lies in how each method uses AI predictions:

\textbf{PPI's Approach.} PPI constructs a ``rectified'' estimator by correcting for prediction error: $\hat{\theta}_{\text{PPI}} = \hat{\theta}_{\text{unlabeled}}(z) + \frac{1}{n_P}\sum_{i \in \mathcal{D}^P}(y_i - z_i)$. This assumes $z$ and $y$ are comparable quantities. The variance of the correction term is $\Var(y - z)/n_P$, which \textit{increases} when predictions are poor. In our setting: (i) $z \in \{-1, 0, 1\}$ is categorical while $y \in \{0, 1\}$ is binary, violating type compatibility; (ii) with 57\% accuracy, $\Var(y - z)$ is large, inflating the correction variance.

\textbf{DML's Approach.} DML learns $g(\bX, \bz) = \E[\by | \bX, \bz]$, treating $\bz$ as a feature rather than assuming $\bz \approx \by$. The relationship between $z$ and $y$ is learned from data, allowing arbitrary mappings. Even when $z$ poorly predicts $y$ marginally, $g(\bX, z)$ can exploit \textit{conditional} patterns---e.g., GPT-4o may systematically favor luxury features, providing signal about preferences for certain consumer segments.

\textbf{When Does PPI Work Well?} PPI is effective when AI predictions are continuous, well-calibrated probabilities close to true outcomes. In classification with $z = P(y=1|X)$ and high accuracy, PPI achieves substantial variance reduction. Our setting violates this: GPT-4o outputs discrete choices, not calibrated probabilities.

Appendix~\ref{app:experiments} provides additional sensitivity analysis showing that DML's advantage grows as AI accuracy decreases, while PPI degrades rapidly below 70\% accuracy.

%============================================================================
\section{Conclusion}
\label{sec:conclusion}
%============================================================================

We introduced a paradigm shift in how AI predictions should be used for statistical inference: as \textit{informative features} rather than \textit{outcome proxies}. This perspective, formalized through Double Machine Learning, enables valid inference even when AI accuracy is moderate---a regime where existing methods like PPI fail. By learning $g(X,z) = \E[y|X,z]$ nonparametrically, our framework extracts signal from AI predictions without assuming they directly approximate human labels.

Our theoretical contributions establish asymptotic normality and prove variance dominance over primary-only estimation under random selection. Empirically, DML achieves state-of-the-art performance on conjoint analysis, reducing MAPE from 32.0\% to 16.5\% (a 48\% relative improvement) versus primary-only estimation. Unlike PPI, which degrades catastrophically at 57\% AI accuracy, DML gracefully handles imperfect predictions by treating them as what they are: informative but imperfect signals.

\textbf{Practical Implications.} Our framework enables researchers and practitioners to leverage abundant AI-generated data while maintaining statistical rigor. The efficiency gains translate to substantial cost savings: achieving the same precision with 50 human labels plus 1000 AI labels versus 200+ human labels represents 75\%+ cost reduction at typical annotation rates.

\textbf{Limitations and Future Work.} Our current framework focuses on canonical GLMs; extensions to non-canonical links and general M-estimators would broaden applicability. While we establish asymptotic dominance, finite-sample guarantees remain an open direction. Finally, adaptive methods that learn when to trust AI predictions (varying $g$ complexity with local AI reliability) could further improve efficiency.

\textbf{When to Prefer Primary-Only Estimation.} Despite the dominance result, practitioners should consider primary-only estimation when: (i) AI predictions are essentially random noise ($z \perp y | X$), offering no information gain; (ii) selection into primary data is highly informative, concentrating labels on high-value observations; or (iii) the cost of obtaining AI predictions exceeds the efficiency benefit, which is rare given current API pricing.

\textbf{Broader Impact.} This work enables more efficient use of human judgment in statistical estimation, potentially reducing annotation costs by 75\%+ while maintaining inferential validity. Positive applications include accelerating market research, medical studies, and social science research where human labels are expensive. However, over-reliance on AI augmentation could reduce demand for human annotators, with labor market implications. Additionally, if AI predictions encode demographic biases, these could propagate into parameter estimates even with our debiasing framework---the method corrects for \textit{accuracy} differences but not necessarily \textit{fairness} differences across subgroups. We recommend auditing AI predictions for disparate accuracy before deployment.

\textbf{Acknowledgments.} [To be added upon acceptance.]

%============================================================================
% References
%============================================================================
\bibliographystyle{plainnat}
\bibliography{references}

%============================================================================
% APPENDIX
%============================================================================
\newpage
\appendix
\onecolumn

\section*{Appendix}

\section{Detailed Proofs}
\label{app:proofs}

\subsection{Notation and Preliminaries}

We use the following notation throughout. Let $\|\cdot\|$ denote the $\ell_2$-norm for vectors and spectral norm for matrices. For a function $f$, define $\|f\|_{P,2} = (\E[\|f\|^2])^{1/2}$. Let $\mathbb{P}_n f = \frac{1}{n}\sum_{i=1}^n f(\Xi_i)$ denote the empirical expectation and $\mathbb{G}_n f = \sqrt{n}(\mathbb{P}_n f - Pf)$ the empirical process. Let $\lambda_{\min}(\cdot)$ denote the minimum eigenvalue.

For the proofs, we split the data into $I$ and $I^c$ of size $n$ each. We train $\hat{e}, \hat{g}$ on $I^c$ and estimate $\hat{\bbeta}$ on $I$. Define the auxiliary quantity:
\begin{equation}
    \btau(\Xi; e, g) := \bX^\top \left[g(\bX, \bz) - \frac{w}{e(\bX, \bz)}(g(\bX, \bz) - \by)\right]
    \label{eq:tau_def}
\end{equation}
so that $\bpsi(\Xi; e, g; \bbeta) = \bX^\top \nabla b(\bX\bbeta) - \btau(\Xi; e, g)$.

\subsection{Proof of Theorem~\ref{thm:normality}}
\label{app:proof_normality}

The proof proceeds through three supporting lemmas.

\begin{lemma}[Score Function Validity and Neyman Orthogonality]
\label{lem:score}
It holds that:
\begin{enumerate}
    \item $P\bpsi(e^*, g^*; \bbeta^*) = 0$
    \item $\mathbb{P}_n\btau(\hat{e}, \hat{g}) - \mathbb{P}_n\btau(e^*, g^*) = o_P(n^{-1/2})$
\end{enumerate}
\end{lemma}

\begin{proof}
\textbf{Part 1.} By the definition of $\btau$:
\begin{align}
    P\btau(e^*, g^*) &= \E\left[\bX^\top \left(g^*(\bX, \bz) - \frac{w}{e^*(\bX, \bz)}(g^*(\bX, \bz) - \by)\right)\right] \\
    &= \E\left[\bX^\top \left(g^*(\bX, \bz) - \frac{\E[w|\bX,\bz]}{e^*(\bX, \bz)}(g^*(\bX, \bz) - \E[\by|\bX,\bz])\right)\right] \\
    &= \E[\bX^\top g^*(\bX, \bz)] - \E[\bX^\top (g^*(\bX, \bz) - g^*(\bX, \bz))] \\
    &= \E[\bX^\top \E[\by|\bX,\bz]] = \E[\bX^\top \by]
\end{align}
where we used $\E[w|\bX,\bz] = e^*(\bX,\bz)$ and $\E[\by|\bX,\bz] = g^*(\bX,\bz)$. Therefore:
\begin{equation}
    P\bpsi(e^*, g^*; \bbeta^*) = \E[\bX^\top \nabla b(\bX\bbeta^*)] - \E[\bX^\top \by] = 0
\end{equation}
by the first-order condition~\eqref{eq:foc}.

\textbf{Part 2.} We decompose:
\begin{align}
    &\sqrt{n}(\mathbb{P}_n\btau(\hat{e}, \hat{g}) - \mathbb{P}_n\btau(e^*, g^*)) \\
    &= \underbrace{\sqrt{n}\mathbb{P}_n\left[\left(1 - \frac{w}{e^*}\right)\bX^\top(\hat{g} - g^*)\right]}_{(I)} + \underbrace{\sqrt{n}\mathbb{P}_n\left[\frac{w(\hat{e} - e^*)}{\hat{e}e^*}\bX^\top(g^* - \by)\right]}_{(II)} \\
    &\quad + \underbrace{\sqrt{n}\mathbb{P}_n\left[\frac{w(\hat{e} - e^*)}{\hat{e}e^*}\bX^\top(\hat{g} - g^*)\right]}_{(III)}
\end{align}

\textbf{Term (I):} Conditional on $I^c$:
\begin{equation}
    \E\left[\left(1 - \frac{w}{e^*(\bX,\bz)}\right)\bX^\top(\hat{g}(\bX,\bz) - g^*(\bX,\bz)) \bigg| I^c\right] = 0
\end{equation}
since $\E[w|\bX,\bz] = e^*(\bX,\bz)$. By Markov's inequality and Assumption~\ref{ass:ml_rate}:
\begin{align}
    P(\|(I)\| \geq \epsilon | I^c) &\leq \frac{\E[\|(I)\|^2 | I^c]}{\epsilon^2} \\
    &\leq \frac{4C^2}{\kappa^2 \epsilon^2} \|\hat{g} - g^*\|_{P,2}^2 \to_P 0
\end{align}

\textbf{Term (II):} Similarly has zero conditional mean since $\E[g^* - \by|\bX,\bz] = 0$. By Assumption~\ref{ass:ml_rate}:
\begin{align}
    P(\|(II)\| \geq \epsilon | I^c) &\leq \frac{2\tilde{\sigma}^2 C^2}{\kappa^2 \epsilon^2} \E[|\hat{e} - e^*|^2 | I^c] + o_P(1) \to_P 0
\end{align}

\textbf{Term (III):} By Cauchy-Schwarz:
\begin{align}
    \E[|\hat{e} - e^*| \|\hat{g} - g^*\|] &\leq \|\hat{e} - e^*\|_{P,2} \|\hat{g} - g^*\|_{P,2} \\
    &\leq \alpha(n)^2 / n^{r_1+r_2} = o(n^{-1/2})
\end{align}
Therefore $(III) = o_P(1)$.
\end{proof}

\begin{lemma}[Rates of Empirical Scores]
\label{lem:rates}
It holds that:
\begin{equation}
    \|\mathbb{P}_n\bpsi(e^*, g^*; \hat{\bbeta})\|, \inf_{\bbeta \in \mathcal{B}} \|\mathbb{P}_n\bpsi(\hat{e}, \hat{g}; \bbeta)\| = o_P(n^{-1/2})
\end{equation}
\end{lemma}

\begin{proof}
Define $\bar{\ell}(\Xi; e, g; \bbeta) := b(\bX\bbeta) - \left[g(\bX,\bz) + \frac{w}{e(\bX,\bz)}(g(\bX,\bz) - \by)\right]^\top \bX\bbeta$, so $\nabla_\bbeta \bar{\ell} = \bpsi$ and $\nabla^2_\bbeta \bar{\ell} = \bX^\top \nabla^2 b(\bX\bbeta) \bX \succeq 0$.

By Lemma~\ref{lem:score}, $P\bar{\ell}(e^*, g^*; \bbeta)$ is strictly convex with unique minimum at $\bbeta^*$. By Theorem 2.7 of \citet{newey1994large}, there exists $\{\check{\bbeta}_n\}$ solving $\min_\bbeta \mathbb{P}_n \bar{\ell}(e^*, g^*; \bbeta)$ with $\check{\bbeta}_n \to_P \bbeta^*$.

Thus $\mathbb{P}_n\bpsi(e^*, g^*; \check{\bbeta}_n) = 0$. By Lemma~\ref{lem:score}:
\begin{equation}
    \sqrt{n}\mathbb{P}_n\bpsi(\hat{e}, \hat{g}; \check{\bbeta}_n) = \sqrt{n}\mathbb{P}_n\bpsi(e^*, g^*; \check{\bbeta}_n) + \sqrt{n}(\mathbb{P}_n\btau(e^*, g^*) - \mathbb{P}_n\btau(\hat{e}, \hat{g})) = o_P(1)
\end{equation}
This gives $\inf_\bbeta \|\mathbb{P}_n\bpsi(\hat{e}, \hat{g}; \bbeta)\| = o_P(n^{-1/2})$, implying $\|\mathbb{P}_n\bpsi(\hat{e}, \hat{g}; \hat{\bbeta})\| = o_P(n^{-1/2})$. Applying Lemma~\ref{lem:score} again yields the result.
\end{proof}

\begin{lemma}[Consistency]
\label{lem:consistency}
$\hat{\bbeta} \to_P \bbeta^*$.
\end{lemma}

\begin{proof}
By the strict convexity established above and uniform convergence of $\mathbb{P}_n\bar{\ell}$ to $P\bar{\ell}$ on compact sets (weak law of large numbers), we have for any $\epsilon_1 < \epsilon_2$ with $B(\bbeta^*, \epsilon_2) \subset \mathcal{B}$:
\begin{equation}
    P\bar{\ell}(e^*, g^*; \bbeta) \geq P\bar{\ell}(e^*, g^*; \bbeta^*) + \frac{c\epsilon_1^2}{2} \quad \forall \bbeta \in B(\bbeta^*, \epsilon_2) \setminus B(\bbeta^*, \epsilon_1)
\end{equation}
for some universal $c > 0$.

By subgradient inequality and the score bounds from Lemma~\ref{lem:rates}, with probability approaching one:
\begin{equation}
    \|\mathbb{P}_n\bpsi(e^*, g^*; \bbeta)\| \geq \frac{c\epsilon_1^2}{4\epsilon_2} \quad \forall \bbeta \in \mathcal{B} \setminus B(\bbeta^*, \epsilon_2)
\end{equation}

Since $\|\mathbb{P}_n\bpsi(e^*, g^*; \hat{\bbeta})\| = o_P(n^{-1/2})$, we must have $\hat{\bbeta} \in B(\bbeta^*, \epsilon_1)$ with probability approaching one.
\end{proof}

\textbf{Completing the proof of Theorem~\ref{thm:normality}.} The score function is locally Lipschitz: for $\bbeta_1, \bbeta_2 \in B(\bbeta^*, \epsilon)$:
\begin{equation}
    \|\bpsi(\Xi; \bbeta_1) - \bpsi(\Xi; \bbeta_2)\| \leq C_1 \|\bX\| \|\bbeta_1 - \bbeta_2\|
\end{equation}
where $C_1 = \sup_{\bbeta \in B(\bbeta^*, \epsilon), \bX \in \mathcal{X}} \|\nabla^2 b(\bX\bbeta)\| < \infty$.

By Example 19.7 and Theorem 19.5 of \citet{vandervaart2000asymptotic}, $\{\bpsi(\cdot; \bbeta) : \bbeta \in B(\bbeta^*, \epsilon)\}$ forms a Donsker class. By Lemma~\ref{lem:consistency} and Theorem 19.9 of \citet{vandervaart2000asymptotic}:
\begin{equation}
    \mathbb{G}_n\bpsi(\hat{\bbeta}) - \mathbb{G}_n\bpsi(\bbeta^*) \to_P 0
\end{equation}

Therefore:
\begin{align}
    \sqrt{n}(P\bpsi(\hat{\bbeta}) - P\bpsi(\bbeta^*)) &= \mathbb{G}_n\bpsi(\hat{\bbeta}) - \mathbb{G}_n\bpsi(\bbeta^*) - \sqrt{n}\mathbb{P}_n\bpsi(\hat{\bbeta}) + \sqrt{n}\mathbb{P}_n\bpsi(\bbeta^*) \\
    &= \sqrt{n}\mathbb{P}_n\bpsi(\bbeta^*) + o_P(1)
\end{align}

By Taylor expansion:
\begin{equation}
    \sqrt{n}\left[P\bX^\top \nabla^2 b(\bX\bbeta^*)\bX (\hat{\bbeta} - \bbeta^*) + o_P(1)\|\hat{\bbeta} - \bbeta^*\|\right] = \sqrt{n}\mathbb{P}_n\bpsi(\bbeta^*) + o_P(1)
\end{equation}

Since $\mathbf{J} = P[\bX^\top \nabla^2 b(\bX\bbeta^*)\bX]$ is invertible:
\begin{equation}
    \sqrt{n}(\hat{\bbeta} - \bbeta^*) = \mathbf{J}^{-1} \sqrt{n}\mathbb{P}_n\bpsi(\bbeta^*) + o_P(1)
\end{equation}

The central limit theorem yields $\sqrt{n}\mathbb{P}_n\bpsi(\bbeta^*) \rightsquigarrow N(0, \E[\bpsi\bpsi^\top])$, completing the proof. \hfill $\square$

\subsection{Proof of Corollary~\ref{cor:dominance}}
\label{app:proof_dominance}

When $e(\bX, \bz) = \rho$ is constant and $w \perp (\bX, \by, \bz)$, define:
\begin{align}
    \zeta(\bX, \bz) &:= \bX^\top(\nabla b(\bX\bbeta^*) - g^*(\bX, \bz)) \\
    \pi(\bX, \by, \bz) &:= \bX^\top(g^*(\bX, \bz) - \by)
\end{align}

Note that $\nabla_\bbeta \ell(\bX, \by; \bbeta^*) = \zeta + \pi$ and $\E[\pi | \bX, \bz] = 0$.

\textbf{Primary-Only Estimator.} The estimator $\hat{\bbeta}^P$ solves $\sum_{i: w_i=1} \nabla_\bbeta \ell(\bX_i, \by_i; \bbeta) = 0$, equivalently $\sum_{i=1}^n w_i \nabla_\bbeta \ell(\bX_i, \by_i; \bbeta) = 0$.

By independence of $w$: $\E[w \nabla_\bbeta \ell(\bX, \by; \bbeta^*)] = \rho \E[\nabla_\bbeta \ell(\bX, \by; \bbeta^*)] = 0$.

Standard arguments yield $\sqrt{n}(\hat{\bbeta}^P - \bbeta^*) \rightsquigarrow N(0, \mathbf{\Sigma}^P)$ where:
\begin{equation}
    \mathbf{\Sigma}^P = \frac{1}{\rho} \mathbf{J}^{-1} \E[(\zeta + \pi)(\zeta + \pi)^\top] \mathbf{J}^{-1}
\end{equation}

Since $\E[\zeta \pi^\top] = \E[\E[\zeta \pi^\top | \bX, \bz]] = \E[\zeta \E[\pi^\top | \bX, \bz]] = 0$:
\begin{equation}
    \mathbf{\Sigma}^P = \frac{1}{\rho} \mathbf{J}^{-1} \E[\zeta\zeta^\top] \mathbf{J}^{-1} + \frac{1}{\rho} \mathbf{J}^{-1} \E[\pi\pi^\top] \mathbf{J}^{-1}
    \label{eq:sigma_p}
\end{equation}

\textbf{DML Estimator.} Observe that $\bpsi(\Xi; e^*, g^*; \bbeta^*) = \zeta(\bX, \bz) + \frac{w}{\rho}\pi(\bX, \by, \bz)$. Therefore:
\begin{align}
    \E[\bpsi\bpsi^\top] &= \E[\zeta\zeta^\top] + \frac{1}{\rho^2}\E[w^2 \pi\pi^\top] + \frac{2}{\rho}\E[w\zeta\pi^\top] \\
    &= \E[\zeta\zeta^\top] + \frac{1}{\rho}\E[\pi\pi^\top]
\end{align}
using $\E[w^2] = \E[w] = \rho$ and $\E[w\zeta\pi^\top] = \rho\E[\zeta\pi^\top] = 0$.

Thus:
\begin{equation}
    \mathbf{\Sigma}^{\text{DML}} = \mathbf{J}^{-1} \E[\zeta\zeta^\top] \mathbf{J}^{-1} + \frac{1}{\rho} \mathbf{J}^{-1} \E[\pi\pi^\top] \mathbf{J}^{-1}
    \label{eq:sigma_dml}
\end{equation}

\textbf{Dominance.} Comparing~\eqref{eq:sigma_p} and~\eqref{eq:sigma_dml}:
\begin{equation}
    \mathbf{\Sigma}^P - \mathbf{\Sigma}^{\text{DML}} = \left(\frac{1}{\rho} - 1\right) \mathbf{J}^{-1} \E[\zeta\zeta^\top] \mathbf{J}^{-1}
\end{equation}

Since $\rho < 1$, we have $\frac{1}{\rho} - 1 > 0$. The matrix $\E[\zeta\zeta^\top]$ is positive semi-definite. It is strictly positive definite when $\E[\bX^\top(\nabla b(\bX\bbeta^*) - g^*)(\cdot)^\top \bX] \succ 0$, i.e., when AI predictions are informative. \hfill $\square$

\section{Applications of the Framework}
\label{app:applications}

\subsection{Canonical GLMs}

A canonical GLM assumes the conditional distribution of $\by$ given $\bX$ belongs to an exponential family:
\begin{equation}
    p_{\text{GLM}}(\by | \btheta) = \exp\left\{\frac{\by^\top \btheta - b(\btheta)}{\phi} + c(\by, \phi)\right\}
\end{equation}
where $\btheta = \bX\bbeta$ is the natural parameter, $b(\cdot)$ is the log-partition function, and $\phi$ is the dispersion parameter.

Under correct specification:
\begin{equation}
    \E[\by | \btheta] = \nabla b(\btheta), \quad \Cov(\by | \btheta) = \nabla^2 b(\btheta)
\end{equation}

Our framework allows misspecification: $\bbeta^*$ is the pseudo-true parameter minimizing KL divergence to the GLM family.

\textbf{Examples:}
\begin{itemize}
    \item \textbf{Linear regression}: $b(\theta) = \frac{1}{2}\theta^2$, $\phi = \sigma^2$
    \item \textbf{Logistic regression}: $b(\theta) = \log(1 + e^\theta)$, $\phi = 1$
    \item \textbf{Poisson regression}: $b(\theta) = e^\theta$, $\phi = 1$
    \item \textbf{Gamma regression}: $b(\theta) = -\log(-\theta)$ for $\theta < 0$
\end{itemize}

\subsection{Multinomial Logit (MNL)}

Fix $k$ alternatives. Covariates are $\bX = (\bX_{(1)}, \ldots, \bX_{(k)})^\top$ with $\bX_{(j)} \in \R^d$. Choice probabilities:
\begin{equation}
    \sigma_j(\bX; \bbeta) = \frac{\exp(\bX_{(j)}^\top \bbeta)}{1 + \sum_{\ell=1}^k \exp(\bX_{(\ell)}^\top \bbeta)}
\end{equation}

This is a canonical GLM with $\btheta_j = \bX_{(j)}^\top \bbeta$ and:
\begin{equation}
    b(\btheta) = \log\left(1 + \sum_{j=1}^k e^{\theta_j}\right)
\end{equation}

\subsection{Example: Failure of Dominance}

We provide a counterexample showing dominance can fail when selection is non-random.

\begin{example}
Consider linear regression with $k=1$, $b(\theta) = \frac{1}{2}\theta^2$. Let $\bx$ follow a mixture: $\tilde{w} = 1$ with probability $p$, and $\E[\bx\bx^\top | \tilde{w}] = \mathbf{I}$ with disjoint supports $\mathcal{X}_0, \mathcal{X}_1$.

Assume $\E[y|\bx] = \bx^\top \bbeta^*$ and $\Var(y|\bx) = \sigma^2_{\tilde{w}}$ when $\bx \in \mathcal{X}_{\tilde{w}}$. Set $z = y - \bx^\top \bbeta$ so $g^*(\bx, z) = y$. Let $e(\bx, z) = 1$ if $\bx \in \mathcal{X}_1$ and $e(\bx, z) = \kappa$ if $\bx \in \mathcal{X}_0$.

Then:
\begin{align}
    \text{AVar}(\hat{\bbeta}^P) &= \frac{p\sigma_1^2 + (1-p)\sigma_0^2 \kappa}{[p + (1-p)\kappa]^2} \mathbf{I} \\
    \text{AVar}(\hat{\bbeta}^{\text{DML}}) &= (p\sigma_1^2 + (1-p)\sigma_0^2) \mathbf{I}
\end{align}

When $\sigma_1, \kappa \to 0$: $\text{AVar}(\hat{\bbeta}^P) \to 0$ while $\text{AVar}(\hat{\bbeta}^{\text{DML}}) \to (1-p)\sigma_0^2 \mathbf{I}$.

Thus dominance fails when selection advantageously excludes high-variance observations.
\end{example}

\section{Additional Experimental Details}
\label{app:experiments}

\subsection{Data Generation}

The conjoint study presents respondents with pairs of sports cars. Each car is characterized by 11 attributes at various levels. For each choice task:
\begin{enumerate}
    \item Two cars are generated with random attribute levels
    \item Respondent chooses preferred car (or neither)
    \item Choice is recorded as $y \in \{0, 1\}$
\end{enumerate}

Ground truth parameters $\bbeta^* \in \R^{11}$ are estimated from a large-scale study with $n > 10,000$ respondents, providing reliable ``true'' values for MAPE calculation.

\subsection{AI Prediction Protocol}

We prompt GPT-4o with:

\begin{quote}
\texttt{You are evaluating car preferences. Given two sports cars with the following attributes, which would a typical consumer prefer?}

\texttt{Car A: [attributes]}

\texttt{Car B: [attributes]}

\texttt{Respond with: 1 (prefer A), 0 (prefer B), or -1 (cannot determine)}
\end{quote}

GPT-4o achieves 57\% accuracy (excluding abstentions), with abstention rate approximately 15\%.

\subsection{Implementation Details}

\textbf{G-Model.} We use stratified logistic regression: for each $z \in \{-1, 0, 1\}$, fit separate logistic regression on primary data with that $z$ value. Regularization $C = 0.05$ produces well-calibrated probabilities.

\textbf{Cross-Fitting.} $K = 5$ folds. For each fold $k$:
\begin{enumerate}
    \item Train $\hat{g}$ on folds $\{1,\ldots,K\} \setminus \{k\}$ (primary data only)
    \item Predict on fold $k$ (primary) and all auxiliary data
    \item Compute $\hat{\bbeta}_k$ by solving the score equation
\end{enumerate}

\textbf{Optimization.} GLM fit using L-BFGS with DML-adjusted targets~\eqref{eq:tau_primary}--\eqref{eq:tau_aux}.

\subsection{Full Results by Sample Size}

\begin{table}[h]
\caption{Complete results across all sample sizes (30 trials each)}
\centering
\begin{tabular}{@{}lcccccc@{}}
\toprule
Method & $n$=50 & $n$=100 & $n$=150 & $n$=200 & Mean & Std \\
\midrule
DML & 17.44 & 16.81 & 16.25 & 15.55 & 16.51 & 0.82 \\
AAE & 20.94 & 17.00 & 16.37 & 16.22 & 17.63 & 2.17 \\
Primary & 55.58 & 29.82 & 22.67 & 19.85 & 31.98 & 16.18 \\
PPI & 93.32 & 48.49 & 33.97 & 28.77 & 51.14 & 29.07 \\
Naive & 128.62 & 100.74 & 85.34 & 73.59 & 97.07 & 23.74 \\
\bottomrule
\end{tabular}
\end{table}

\subsection{Economic Interpretation}

\begin{table}[h]
\caption{Economic interpretation: estimation error in willingness-to-pay (\$1000s per attribute)}
\label{tab:wtp}
\centering
\begin{tabular}{@{}lccc@{}}
\toprule
Method & Avg MAPE & WTP Error & vs.\ DML \\
\midrule
\textbf{DML} & 16.5\% & \$0.58K & --- \\
Primary Only & 32.0\% & \$1.12K & +\$0.54K \\
AAE & 17.6\% & \$0.62K & +\$0.04K \\
PPI & 51.1\% & \$1.79K & +\$1.21K \\
\bottomrule
\end{tabular}
\end{table}

With average true WTP of \$3.5K per attribute, the MAPE directly translates to dollar estimation error. DML's improvement over Primary Only saves \$540 per attribute, or \$5,940 across all 11 attributes---a meaningful difference for pricing and product design decisions.

\subsection{Sensitivity Analysis}

\textbf{Number of Folds.} Results are robust to $K \in \{3, 5, 10\}$, with $K=5$ providing good bias-variance tradeoff.

\textbf{G-Model Regularization.} Strong regularization ($C \in [0.01, 0.1]$) outperforms weak regularization ($C \geq 1$), as calibrated probabilities matter more than classification accuracy.

\textbf{Auxiliary Sample Size.} Performance improves with $n_A$ up to approximately $10 \times n_P$, with diminishing returns thereafter.

\end{document}
